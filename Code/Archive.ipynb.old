{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "def skip_rows(index):\n",
    "    return index % 20 != 0\n",
    "\n",
    "# Load your dataset, skipping rows\n",
    "df2023 = pd.read_csv('2023.prcp.us.csv', header=None, skiprows=lambda x: skip_rows(x))\n",
    "df2022= pd.read_csv('2022.prcp.us.csv', header=None, skiprows=lambda x: skip_rows(x))\n",
    "df=pd.concat([df2022,df2023.iloc[:,1:13]],axis=1)\n",
    "df.columns = ['Latitude', 'Longitude'] + [f'Month_{i}' for i in range(1, 25)]\n",
    "\n",
    "# Convert the dataset to long format for easier plotting with Plotly\n",
    "df_long = df.melt(id_vars=['Latitude', 'Longitude'], var_name='Month', value_name='Precipitation')\n",
    "\n",
    "# Create the interactive map\n",
    "fig = px.scatter_geo(df_long,\n",
    "                     lat='Latitude',\n",
    "                     lon='Longitude',\n",
    "                     color='Precipitation',\n",
    "                     animation_frame='Month',\n",
    "                     #scope='usa',  # Focus the map on the United States\n",
    "                     projection=\"natural earth\",\n",
    "                     title=\"US 2023 Monthly Precipitation\")\n",
    "\n",
    "fig.update_geos(\n",
    "    lataxis_range=[24.52, 49.38],  # Latitude range\n",
    "    lonaxis_range=[-124.77, -66.95]  # Longitude range\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your datasets\n",
    "# Replace 'your_actual_dataset.csv' and 'your_average_dataset.csv' with the actual file paths\n",
    "df_actual_2022 = pd.read_csv('2022.prcp.us.csv', header=None, skiprows=lambda x: x % 20 != 0)\n",
    "df_actual_2023 = pd.read_csv('2023.prcp.us.csv', header=None, skiprows=lambda x: x % 20 != 0)\n",
    "df_average = pd.read_csv('us_prcp_1901-2000_normal.csv', header=None, skiprows=lambda x: x % 20 != 0)\n",
    "\n",
    "# Assuming the first two columns are latitude and longitude, and the rest are the monthly values\n",
    "# Ensure that both DataFrames have the same structure\n",
    "df_actual_2022.columns = ['Latitude', 'Longitude'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "df_actual_2023.columns = ['Latitude', 'Longitude'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "df_average.columns = ['Latitude', 'Longitude'] + [f'Month_{i}' for i in range(1, 13)]\n",
    "\n",
    "# Calculate the anomaly (actual - average)\n",
    "df_anomaly_2022 = df_actual_2022.copy()\n",
    "df_anomaly_2023 = df_actual_2023.copy()\n",
    "df_anomaly_2022.iloc[:, 2:] = df_actual_2022.iloc[:, 2:] - df_average.iloc[:, 2:]*25.4\n",
    "df_anomaly_2023.iloc[:, 2:] = df_actual_2023.iloc[:, 2:] - df_average.iloc[:, 2:]*25.4\n",
    "\n",
    "# Convert the anomaly dataset to long format for easier plotting with Plotly\n",
    "df_long_anomaly = df_anomaly_2022.melt(id_vars=['Latitude', 'Longitude'], var_name='Month', value_name='Anomaly')\n",
    "\n",
    "# Rest of your processing and visualization code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_color_scale = [\n",
    "    (0.0, \"red\"),            # Red for the lowest values\n",
    "    #(0.19, \"red\"),           # Transition start from red to gray\n",
    "    (0.3, \"lightgray\"),      # Light gray at 20th percentile\n",
    "    (0.4, \"gray\"),           # Gray in the middle\n",
    "    (0.6, \"gray\"),           # Gray in the middle\n",
    "    (0.7, \"lightgray\"),      # Light gray at 80th percentile\n",
    "    #(0.81, \"blue\"),          # Transition start from gray to blue\n",
    "    (1.0, \"blue\")            # Blue for the highest values\n",
    "]\n",
    "\n",
    "# Create the interactive map with the custom color scale\n",
    "figA = px.scatter_geo(df_long_anomaly,\n",
    "                     lat='Latitude',\n",
    "                     lon='Longitude',\n",
    "                     color='Anomaly',\n",
    "                     animation_frame='Month',\n",
    "                     projection=\"natural earth\",\n",
    "                     color_continuous_scale=custom_color_scale,\n",
    "                     title=\"US 2023 Monthly Precipitation Anomaly\")\n",
    "\n",
    "figA.update_geos(\n",
    "    lataxis_range=[24.52, 49.38],  # Latitude range\n",
    "    lonaxis_range=[-124.77, -66.95]  # Longitude range\n",
    ")\n",
    "\n",
    "figA.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=0.2\n",
    "mat=np.zeros(shape=(24,int((49.38-24.52)/grid)+1,int((-66.95+124.77)/grid)+1))#month,lat,lon\n",
    "for ind,e in df_anomaly_2022.iterrows():\n",
    "    for j in range(1,13):\n",
    "        #print(e['Latitude'],e['Longitude'])\n",
    "        mat[j-1][int((e['Latitude']-24.52)/grid)][int((e['Longitude']+124.77)/grid)]=max(mat[j-1][int((e['Latitude']-24.52)/grid)][int((e['Longitude']+124.77)/grid)],e[1+j])\n",
    "\n",
    "for ind,e in df_anomaly_2023.iterrows():\n",
    "    for j in range(1,13):\n",
    "        #print(e['Latitude'],e['Longitude'])\n",
    "        mat[j-1+12][int((e['Latitude']-24.52)/grid)][int((e['Longitude']+124.77)/grid)]=max(mat[j-1][int((e['Latitude']-24.52)/grid)][int((e['Longitude']+124.77)/grid)],e[1+j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 125, 290)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            climate change  isPartial\n",
      "date                                 \n",
      "2022-01-02               2      False\n",
      "2022-01-09               2      False\n",
      "2022-01-16               1      False\n",
      "2022-01-23               2      False\n",
      "2022-01-30               2      False\n",
      "...                    ...        ...\n",
      "2023-12-03               3      False\n",
      "2023-12-10               3      False\n",
      "2023-12-17               1      False\n",
      "2023-12-24               1      False\n",
      "2023-12-31               1      False\n",
      "\n",
      "[105 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "from datetime import datetime\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "kw_list = [\"climate change\"]\n",
    "\n",
    "# Set the start date to the beginning of 2023 and the end date to today (or the last date in 2023 you're interested in)\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "#end_date = datetime.today().strftime('%Y-%m-%d')  # Today's date in YYYY-MM-DD format; adjust as needed\n",
    "\n",
    "# Build the payload with the adjusted timeframe\n",
    "pytrends.build_payload(kw_list, cat=0, timeframe=f'{start_date} {end_date}', geo='US', gprop='')\n",
    "\n",
    "# Interest over time\n",
    "interest_over_time_df = pytrends.interest_over_time()\n",
    "print(interest_over_time_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.   8.   9. 114.  16.   6.   9.   8.  10.  15.  11.   9.  11.  11.\n",
      "  11.  54.  12.   6.  10.   8.  11.  12.  11.   9.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "GTbyMonth = np.zeros(24)\n",
    "for m in range(1, 13):\n",
    "    # Generate the start and end date for each month\n",
    "    start_date = datetime(2022, m, 1)\n",
    "    end_date = pd.date_range(start_date, periods=1, freq='M').date[0]  # 'M' frequency stands for month end\n",
    "\n",
    "    # Use the generated start and end dates to filter the DataFrame\n",
    "    Monthlydf = interest_over_time_df.loc[start_date:end_date]\n",
    "\n",
    "    # Sum the values for the month and assign to the corresponding position in GTbyMonth\n",
    "    GTbyMonth[m-1] = int(Monthlydf['climate change'].sum())  # Adjusted index to m-1 since Python is zero-indexed\n",
    "\n",
    "for m in range(1, 13):\n",
    "    # Generate the start and end date for each month\n",
    "    start_date = datetime(2023, m, 1)\n",
    "    end_date = pd.date_range(start_date, periods=1, freq='M').date[0]  # 'M' frequency stands for month end\n",
    "\n",
    "    # Use the generated start and end dates to filter the DataFrame\n",
    "    Monthlydf = interest_over_time_df.loc[start_date:end_date]\n",
    "\n",
    "    # Sum the values for the month and assign to the corresponding position in GTbyMonth\n",
    "    GTbyMonth[m-1+12] = int(Monthlydf['climate change'].sum())  # Adjusted index to m-1 since Python is zero-indexed\n",
    "\n",
    "print(GTbyMonth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 125, 290, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 123, 288, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 61, 144, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 59, 142, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 29, 71, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 131776)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16867456  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,886,401\n",
      "Trainable params: 16,886,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Corrected input shape to match the provided data\n",
    "spatial_input = Input(shape=(mat.shape[1],mat.shape[2], 1))  # Shape adjusted to (height, width, channels)\n",
    "\n",
    "# Example CNN architecture\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(spatial_input)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "flat = Flatten()(pool2)\n",
    "dense1 = Dense(128, activation='relu')(flat)\n",
    "output = Dense(1, activation='linear')(dense1)  # Assuming a regression task\n",
    "\n",
    "# Create the model with the corrected input shape\n",
    "model = Model(inputs=spatial_input, outputs=output)\n",
    "\n",
    "# Model summary to verify the input shape\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mat\n",
    "X_normalized = (X - X.min()) / (X.max() - X.min())\n",
    "X_reshaped = X_normalized[..., np.newaxis]\n",
    "model.compile(optimizer='adam', loss='mse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 934.0715 - val_loss: 76.2454\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 887.4233 - val_loss: 35.3732\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 806.4567 - val_loss: 15.2439\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 694.8845 - val_loss: 133.2050\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 624.4861 - val_loss: 463.0757\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 703.3589 - val_loss: 390.4833\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 660.8423 - val_loss: 222.7180\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 597.9500 - val_loss: 109.3720\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 575.6867 - val_loss: 56.9601\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 576.8725 - val_loss: 37.2498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ffc70e3d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming X_spatial and X_temporal are your prepared spatial and temporal features, and y are your target labels\n",
    "model.fit(x=X_reshaped,y=GTbyMonth, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
